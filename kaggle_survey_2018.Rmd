---
title: "Becoming Data Scientist without a Computer Science Major"
author: "Muhsina Elampilakkattil"
date: "20 November 2018"
output: 
  html_document:
    toc: true
    fig_height: 5
    fig_width: 6
    code_folding: hide
---
<hr/>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction 
Harvard Business Review described Data Science as the sexiest job of the 21st century. 

>*Data Science is all about manipulating large and unstructured data sources and creates insights from them.* 

Data Scientist has become one of the most sought-after disciplines in our world of increasing data. And data scientists seem to come from the diverse educational background.  Even though people ask questions like, "Can anyone from a non-computer science background be a data scientist?" "How can I be data scientist with a non-computer science background?".  The most common questions from some aspiring data scientists. In fact,  the same questions which I googled 7 months back.

 There are so many people from diverse backgrounds trying to get this hottest job. Some of them think this job is meant for people from the computer science background. 
My educational background is in Finance and Accounting. When I started thinking about a career in data science, I had lots of questions flying over my head.  What programming language do I have to learn? Which online source will help me learning to programme? etc..
 
 I thought it would be better if I get answers for these questions from people who are currently working as data scientists and from the non-computer science background. But I could not get connected to anyone like this to clear my doubts. 

When I came across the Kaggle Data Science & Machine Learning Survey 2018, I decided to analyse the responses from people who already working as a data scientist and with a non-computer science major.  In this exploratory analysis, I will be narrating some ways that may help aspiring data scientists without a computer science background. 


###About the Dataset 

 Kaggle conducted a worldwide survey to know about the state of data science and machine learning. The survey was live for one week in October. The datasets include 23,859 responses and 395 variables. These variables are the answers to survey questions. 

When survey respondents selected the "Other" category, an option was given for a text response. These text responses were separated and shuffled to protect user privacy.

We need to load multiple libraries and datasets to start the analysis.

```{r, message= FALSE, warning= FALSE}
library(tidyverse)
library(RColorBrewer)
library(ggthemes)
library(gridExtra)
library(cowplot)

#Load data
other<- read_csv("datasets/freeFormResponses.csv")
survey<- read_csv("datasets/multipleChoiceResponses.csv")
schema<- read_csv("datasets/SurveySchema.csv");

#Storing questions in a long data frame for reference
questions<- read_csv("datasets/multipleChoiceResponses.csv", n_max= 1)
questions<- gather(questions, column, descr)

#Remove the row with the long questions
survey<- survey[-1, ]
other<- other[-1, ]
```
###Types of Data Scientists

Data science is a complex and often confusing field. Data science combines several disciplines, including statistics, data analysis, machine learning, and computer science. 
According to a featured [article](https://blog.udacity.com/2018/01/4-types-data-science-jobs.html) in Udacity, there are four types of data science jobs.
 - The Data Analyst
There are some companies where being a data scientist is synonymous with being a data analyst. Your job might consist of tasks like pulling data out of SQL databases, becoming an Excel or Tableau master, and producing basic data visualizations and reporting dashboards. You may on occasion analyze the results of an A/B test or take the lead on your company’s Google Analytics account. 
 - The Data Engineer
Some companies get to the point where they have a lot of traffic (and an increasingly large amount of data), and they start looking for someone to set up a lot of the data infrastructure that the company will need moving forward. They’re also looking for someone to provide analysis. You’ll see job postings listed under both “Data Scientist” and “Data Engineer” for this type of position. Since you’d be (one of) the first data hires, heavy statistics and machine learning expertise is less important than strong software engineering skills. 
 - The Machine Learning Engineer
There are a number of companies for whom their data (or their data analysis platform) is their product. In this case, the data analysis or machine learning going on can be pretty intense. This is probably the ideal situation for someone who has a formal mathematics, statistics, or physics background and is hoping to continue down a more academic path. 
 - The Data Science Generalist
A lot of companies are looking for a generalist to join an established team of other data scientists. The company you’re interviewing for cares about data but probably isn’t a data company. It’s equally important that you can perform analysis, touch production code, visualize data, etc.

“Some of the most important ‘data generalist’ skills are familiarity with tools designed for ‘big data,’ and experience with messy, ‘real-life’ datasets.”

###Data Scientists Subset

In this analysis, we are grouping Data Scientists, Data Analysts, and Data Engineers together as Data Scientists subset.  We are considering undergraduate major (Question 4) as the attribute to subset the data as respondents working as data scientists with a non-computer science major. We need to filter out responses with an option "I am a student" to the Question 7 (In what industry is your current employer/contract?) to ensure the respondent is working as a data scientist. 

**Note: Throughout this analysis, Data Scientists means people who responded their current job title or role as any of Data scientist, data analyst, or data engineer in the survey.**

```{r}

#Subset responses from non computer science major
NonCS<- survey%>%
filter(Q5 != "Computer science (software engineering, etc.)",
      Q6 %in% c("Data Scientist", "Data Engineer", "Data Analyst"),
      !is.na(Q8),
      Q7 != "I am a student")  
```
#Data Scientists with Non-Computer Science Major
It's widely assumed that you will need a formal education in Computer Science to pursue a career in data science. The definition and job description of data scientists vary from company to company. But it's clear that a data scientist should be able to manipulate large and unstructured data and create insights from them.
Studies have shown that data scientists come from diverse backgrounds.

Out of the 23859 responses in the Kaggle Survey 2018, **25% of respondents are currently working as data scientists**. 
```{r}
#Data Scientists
survey%>%
  filter(Q6 %in% c("Data Scientist", "Data Engineer", "Data Analyst"),
      !is.na(Q8),
       !is.na(Q5),
      Q7 != "I am a student") %>%  
  mutate(CS= ifelse(Q5=="Computer science (software engineering, etc.)", TRUE, FALSE)) %>%
  select(Q6, CS)   %>%
  group_by(Q6, CS)  %>%
  summarize(n= n()) %>%
  mutate(pct = n/ sum(n) * 100 ) %>%
    ggplot(aes(x= reorder(Q6, n), y = n, fill= factor(CS, levels= c(TRUE,FALSE)))) + 
    geom_bar(stat = "identity", position= "dodge") + 
    scale_fill_manual(values = c("gray70","dodgerblue4"),  name="Undergraduate Major",
                       breaks=c(FALSE, TRUE),
                       labels=c("Non-Computer Science", "Computer Science")) +
    labs(title= "Data Scientists", x="", y="Count") +
    annotate("text", x = "Data Analyst", y = 1228, label = "73.8%", hjust= 1, vjust= -1.5, color= "white") +
    annotate("text", x = "Data Engineer", y = 316, label = "47.4%", hjust= 1, vjust= -1.5, color= "white") +
    annotate("text", x = "Data Scientist", y = 2529, label = "67.7%", hjust= 1, vjust= -1.5, color= "white") +
    coord_flip() + 
    theme(axis.ticks = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background= element_blank(), legend.position="bottom")
```

I think you have got the answer to the first question.Can anyone from a non-computer science background be a data scientist? 

Of course, yes! 

67% of the data scientists are from no-computer science backgrounds. They are from diverse backgrounds like Social science, mathematics, and statistics, business disciplines, fine arts, humanities, etc.

It's time to know how to become a data scientist without a computer science major.

#1. Find out if it's really for you
We know data scientists are from diverse educational backgrounds. Before seeking how to learn the skills needed, make sure it's really for you. It requires continuous learning and practicing of complex concepts. 
Let's get to know the selected data scientists in detail. 

##Education

We identified a set of working data scientists with a non-computer science major from the kaggle survey data. They are 4073 in total. What about their highest level of formal education?


```{r}

#Employment Industry
NonCS%>%
count(Q7) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q7, n), y= n)) +
  geom_bar(stat= "identity", fill= "blue") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "EmploymentIndustry (Non CS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

#Education
NonCS%>%
count(Q4) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
head(5)%>%
  ggplot(aes(x= reorder(Q4, n), y= n)) +
  geom_bar(stat= "identity", fill= "royalblue4") +
  geom_text(aes(label= paste0(round(pct,1),"%", sep="", hjust= 0)),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Education (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)
```

95% of the data scientists are having at least a bachelors degree. 

###Activities Important as a Data Scientist
It's important to know the daily activities you'll have to do in your work once you are a data scientist. 

```{r}
#Activities important in the current role
(activities<- NonCS%>%
  select(matches("Q11_Part")) %>%
  gather(Part, Activities, na.rm=TRUE) %>%
  group_by(Activities) %>%
  summarize(count= n()) %>%
  arrange(desc(count)))


# Core wrapping function
wrap.it <- function(x, len)
{ 
  sapply(x, function(y) paste(strwrap(y, len), 
                              collapse = "\n"), 
         USE.NAMES = FALSE)
}


# Call this function with a list or vector
wrap.labels <- function(x, len)
{
  if (is.list(x))
  {
    lapply(x, wrap.it, len)
  } else {
    wrap.it(x, len)
  }
}


label <- wrap.labels(activities$Activities, 30)

activities%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(Activities, desc(count)), y= count)) +
  geom_bar(stat= "identity", fill= "blue") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "Activities important in the current role (NonCS)", x= "", y= "Count") +
    scale_x_discrete(labels= wrap.labels(activities$Activities, 30))+
  coord_flip() +
  theme_minimal(base_size= 8)
```

The important activities of a data scientist are to analyze and understand data to influence product or business decisions. Along with, you may have to do the following:
 - Build prototypes to explore applying machine learning to new areas 
 - Build and/or run a machine learning service that operationally improves my product or workflows
 - Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data
 - Do research that advances the state of the art of machine learning
 
###Time spend for coding
58% of the data scientists use more than half of their time actively coding. 
```{r}
#Coding time
NonCS%>%
filter(!(Q23 %in% c(NA, "I do not wish to disclose my approximate yearly compensation"))) %>%
count(Q23) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q23,n), y= n)) +
  geom_bar(stat= "identity", fill= "royalblue4") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Coding Time (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)
```
 
###Primary Tools and IDEs

More than half of the data scientists use local or hosted development environments like R Studio, Jupyter Lab, etc.

```{r}
#Primary tool use at work
NonCS%>%
filter(!is.na(Q12_MULTIPLE_CHOICE)) %>%
count(Q12_MULTIPLE_CHOICE) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q12_MULTIPLE_CHOICE, n), y= n)) +
  geom_bar(stat= "identity", fill= "blue") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Primary tool use at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


#IDEs used
IDE<- NonCS%>%
  select(matches("Q13_Part")) %>%
  gather(Part, IDEs, na.rm=TRUE) %>%
  group_by(IDEs) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

IDE%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(IDEs, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "IDEs used at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

```

35% of the data scientists use Jupyter Notebook/ IPython and RStudio. 

###Programming Languages 
Python take the leading posiotion among data scientists. 70% of the data scientists use any of Python, SQL, and R for programming.
 78% of the data scientists use Python or R regularly at work.
Majority of the data scientists recommend aspiring data scientists to start by learning python. 
```{r}
#Programming laguages used at work
lang<- NonCS%>%
  select(matches("Q16_Part")) %>%
  gather(Part, languages, na.rm=TRUE) %>%
  group_by(languages) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

lang%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(languages, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "Programming languages used at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

#Mostly used programming language
NonCS%>%
filter(!is.na(Q17)) %>%
count(Q17) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q17, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Language use at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

#Language recommendation
NonCS%>%
filter(!is.na(Q18)) %>%
count(Q18) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q18, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Language recommend (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

# Grouping by language_preference and then LanguageRecommendationSelect
recommendations <- NonCS  %>% 
    group_by(Q17, Q18)  %>% 
    summarize(count= n()) %>%

# Removing empty responses and include the top recommendations
    filter(Q18 != "NA",
          Q17 %in% c("Python", "R")) %>%
    arrange(Q17, desc(count)) %>%
    mutate(row_n = row_number()) %>%
    filter(row_n <= 4)
recommendations

# Creating a faceted bar plot
ggplot(recommendations, aes(x= Q18, y = count))+ geom_bar(stat = "identity", fill= "royalblue4") +
    facet_wrap(~ Q17, scales = "free_x") +
    theme(axis.ticks = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background= element_blank(), legend.position="bottom")

```

Data Scientists who use Python and R recommend learning python first.
If you still need a career in Data Science, better you start with learning Python.


##2.Acquire Additional Skills
Even though you are not from a computer science background, you may know some programming languages. Understand what skills you have and what not. 
Let's see how data scientists acquired their analytical and programming skills.

###Online Platform
80% of the data scientists have used at least one online platform of Coursera, DataCamp, Udemy, Udacity, edX and Kaggle Learn.
More than half of them have spent most of their time learning from Coursera and DataCamp. 
Your knowledge about data science needs to be updated. You can get knowledge on data science topic by following media like Kaggle forums, Medium, KDnuggets blog, etc. 
It's always better to follow multiple media. 

```{r}
#online platform
online<- NonCS%>%
  select(matches("Q36_Part")) %>%
  gather(Part, platform, na.rm=TRUE) %>%
  group_by(platform) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

online%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(platform, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "online platforms (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%
filter(!is.na(Q37)) %>%
count(Q37) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q37, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Online platform mostly used (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

#media
media<- NonCS%>%
  select(matches("Q38_Part")) %>%
  gather(Part, media, na.rm=TRUE) %>%
  group_by(media) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

media%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(media, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "media source (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)

```

###Most Popular Frameworks and Libraries
####Machine Learning Framework
 - Scikit-Learn
 This Python module based on NumPy and SciPy is one of the best libraries for working with data. It provides algorithms for many standard machine learning and data mining tasks such as clustering, regression, classification, dimensionality reduction, and model selection.
 - TensorFlow
 TensorFlow is a popular framework for deep and machine learning, developed in Google Brain. It provides abilities to work with artificial neural networks with multiple data sets. Among the most popular TensorFlow applications are object identification, speech recognition, and more. There are also different layer-helpers on top of regular TensorFlow, such as tflearn, tf-slim, skflow, etc.
 - Keras
 Keras is a high-level library for working with neural networks, running on top of TensorFlow, Theano, and now as a result of the new releases, it is also possible to use CNTK and MxNet as the backends. It simplifies many specific tasks and greatly reduces the amount of monotonous code. However, it may not be suitable for some complicated things.
 

####Data Visualization Library
Data Visualization is a very important in data analysis. You can visualize the data to get quick insights from the large and unstructured data. Most commonly used data visualization libraries are:
 - Matplotlib
 Matplotlib is the mostly used data visualization library. Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. You can generate plots, histograms, power spectra, bar charts, errorcharts, scatterplots, etc., with just a few lines of code. 
 - ggplot2
 ggplot2 is one of the most popular packages for data visualization among R users. ggplot2 follows the '[grammar of graphics](https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448/ref=as_li_ss_tl?ie=UTF8&qid=1477928463&sr=8-1&keywords=the+grammar+of+graphics&linkCode=sl1&tag=ggplot2-20&linkId=f0130e557161b83fbe97ba0e9175c431)' to create elegant data visualizations. 
 - Seaborn
Seaborn is a Python data visualization library built on top of matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.

```{r}
#Machine learning framework
mlFramework<- NonCS%>%
  select(matches("Q19_Part")) %>%
  gather(Part, framework, na.rm=TRUE) %>%
  group_by(framework) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

mlFramework%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(framework, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "ML Framework used at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%
filter(!is.na(Q20)) %>%
count(Q20) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q20, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "ML framework mostly used (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


dataVizLib<- NonCS%>%
  select(matches("Q21_Part")) %>%
  gather(Part, library, na.rm=TRUE) %>%
  group_by(library) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

dataVizLib%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(library, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "Dataviz libraries used at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%
filter(!is.na(Q22)) %>%
count(Q22) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q22, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "DataViz library mostly used (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%
filter(!is.na(Q22)) %>%
count(Q22) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q22, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "DataViz library mostly used (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%
filter(!is.na(Q26)) %>%
count(Q26) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q26, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Are you a DS? (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


#Data used
data<- NonCS%>%
  select(matches("Q31_Part")) %>%
  gather(Part, type, na.rm=TRUE) %>%
  group_by(type) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

data%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(type, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "data types used at work (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


NonCS%>%



#Datasets
datasets<- NonCS%>%
  select(matches("Q33_Part")) %>%
  gather(Part, datasets, na.rm=TRUE) %>%
  group_by(datasets) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

datasets%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(datasets, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "public datasets (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)
```

##End-to-end Projects
After acquiring basic analytical and programming knowledge, start doing real-world projects to boost your knowledge. Doing projects is the best way to show skills in your portfolio. You can download lots of public datasets from various sites. 

```{r}
#Public datasets
datasets<- NonCS%>%
  select(matches("Q33_Part")) %>%
  gather(Part, dataset, na.rm=TRUE) %>%
  group_by(dataset) %>%
  summarize(count= n()) %>%
  arrange(desc(count))

datasets%>%
mutate(pct = count/ sum(count) * 100 ) %>%
arrange(desc(count)) %>%
  ggplot(aes(x= reorder(dataset, count), y= count)) +
  geom_bar(stat= "identity", fill= "burlywood1") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 3)+
  labs(title= "Public datasets (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)


#datatypes mostly used at work
filter(!is.na(Q32)) %>%
count(Q32) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ggplot(aes(x= reorder(Q32, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
  geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Data types mostly deal with (NonCS)", x= "", y= "Count") +
  coord_flip() +
  theme_minimal(base_size= 8)
```

Data scientists deals with different type of data like, numerical, categorical, time series, text, etc. 

```{r}
#Independent project vs academic achievement

 NonCS %>%
  select(Q40)%>%
  filter(!is.na(Q40)) %>%
  count(Q40) %>%
mutate(pct = n/ sum(n) * 100 ) %>%
arrange(desc(n)) %>%
  ungroup() %>%
  ggplot(aes(x= reorder(Q40, n), y= n)) +
  geom_bar(stat= "identity", fill= "darksalmon") +
   geom_text(aes(label= paste0(round(pct,2),"%", sep="")),
      position= position_dodge(0), color= "black", size= 2.5)+
  labs(title= "Independent Project Vs. Academic Achievements", x= "", y= "Count") +
  scale_x_discrete(labels = function(x) lapply(str_wrap(x, width = 25), paste, collapse="\n")) +
  coord_flip() +
theme(axis.ticks = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background= element_blank(), axis.text.y= element_text(size= 8))


```

Majority of their opinion is independent project are important than academic achievements. 







##References
1. https://medium.com/activewizards-machine-learning-company/top-20-python-libraries-for-data-science-in-2018-2ae7d1db8049
2. 